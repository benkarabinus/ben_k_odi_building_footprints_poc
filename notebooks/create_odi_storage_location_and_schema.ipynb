{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fbb3b433-a025-4be4-94fa-abaa84c80631",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 1"
    }
   },
   "source": [
    "# ODI Building Footprints Pipeline - Setup\n",
    "\n",
    "This notebook creates the required Unity Catalog infrastructure for the ODI building footprints processing pipeline.\n",
    "\n",
    "## Purpose\n",
    "This is a **prerequisite setup notebook** that must be run before executing the ODI building footprints job. It creates:\n",
    "* **Catalog**: `odi_datalake` - The Unity Catalog namespace for all ODI data\n",
    "* **Schemas**: `odi_bronze`, `odi_silver`, `odi_gold` - The medallion architecture layers for data processing\n",
    "* **Volume**: `supporting_geometry_files` in `odi_bronze` - Storage for geometry reference files\n",
    "\n",
    "## Prerequisites\n",
    "* Unity Catalog enabled in your Databricks workspace\n",
    "* Appropriate permissions to create catalogs and schemas\n",
    "* (Optional) External storage location configured for the catalog\n",
    "\n",
    "## Usage\n",
    "1. Review and update the configuration variables in the configuration cell\n",
    "2. Run all cells in sequence\n",
    "3. Verify the catalog and schemas are created successfully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b6d2d3a-258c-4e96-8f93-b1b774857036",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 2"
    }
   },
   "source": [
    "## Configuration Options\n",
    "\n",
    "### Catalog Storage Location\n",
    "You can specify an external storage location for the catalog in two ways:\n",
    "\n",
    "* **Using an existing Unity Catalog external location** (recommended):\n",
    "  * Reference by name: `\"odi_datalake\"`\n",
    "  * The external location must already be created in Unity Catalog with proper credentials\n",
    "  * This is the cleanest approach as credentials are managed centrally\n",
    "  * [Learn how to create external locations in Azure Databricks](https://learn.microsoft.com/en-us/azure/databricks/connect/unity-catalog/cloud-storage/external-locations)\n",
    "\n",
    "* **Without external location** (default metastore):\n",
    "  * Suitable for POC and development\n",
    "  * Data stored in workspace's default metastore location\n",
    "  * Leave `catalog_storage_location` as empty string\n",
    "\n",
    "### Medallion Architecture\n",
    "The pipeline uses a standard medallion architecture:\n",
    "* **odi_bronze**: Raw ingested data\n",
    "* **odi_silver**: Cleaned and validated building footprints\n",
    "* **odi_gold**: Aggregated and business-ready datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "023b69d1-3868-472a-abab-da9ec466c170",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 1"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration - Update these values for your environment\n",
    "catalog = \"odi_datalake\"\n",
    "catalog_storage_location = \"odi_datalake\"  # External location name (must already exist in Unity Catalog). Leave empty string \"\" to use default metastore.\n",
    "\n",
    "# Create odi_datalake catalog\n",
    "catalogs = [row.catalog for row in spark.sql(\"SHOW CATALOGS\").collect()]\n",
    "if catalog not in catalogs:\n",
    "    # Use external location if specified (preferred)\n",
    "    if catalog_storage_location:\n",
    "        spark.sql(f\"CREATE CATALOG {catalog} MANAGED LOCATION '{catalog_storage_location}'\")\n",
    "        print(f\"Created catalog {catalog} with external location: {catalog_storage_location}\")\n",
    "    # Else default metastore (okay for POC but not preferred)\n",
    "    else:\n",
    "        spark.sql(f\"CREATE CATALOG {catalog}\")\n",
    "        print(f\"Created catalog {catalog} (using default metastore storage)\")\n",
    "else:\n",
    "    print(f\"Catalog {catalog} already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2fcd9f21-9df8-49f1-b688-e3f966e9b6e5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 2"
    }
   },
   "outputs": [],
   "source": [
    "# Create odi_bronze, odi_silver, and odi_gold schemas in the odi_datalake catalog\n",
    "required_schemas = [\"odi_bronze\", \"odi_silver\", \"odi_gold\"]\n",
    "for schema in required_schemas:\n",
    "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.{schema}\")\n",
    "    print(f\"Created schema {schema} in catalog {catalog}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0159f5d-c440-4d53-9602-7d1d61308975",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create volume for geometry files"
    }
   },
   "outputs": [],
   "source": [
    "# Create volume for supporting geometry files in odi_bronze\n",
    "volume_name = \"supporting_geometry_files\"\n",
    "volume_path = f\"{catalog}.odi_bronze.{volume_name}\"\n",
    "\n",
    "# Check if volume already exists\n",
    "existing_volumes = spark.sql(f\"SHOW VOLUMES IN {catalog}.odi_bronze\").collect()\n",
    "if any(row.volume_name == volume_name for row in existing_volumes):\n",
    "    print(f\"Volume {volume_path} already exists\")\n",
    "else:\n",
    "    spark.sql(f\"CREATE VOLUME IF NOT EXISTS {volume_path}\")\n",
    "    print(f\"Created volume {volume_path}\")\n",
    "    print(f\"Access path: /Volumes/{catalog}/odi_bronze/{volume_name}\")\n",
    "    print(f\"State geometries path: /Volumes/{catalog}/odi_bronze/{volume_name}/state_geometries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d65ab079-2c59-41f9-a171-c3e6c56a9723",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create volume for output files"
    }
   },
   "outputs": [],
   "source": [
    "# Create volume for output files (GeoParquet and Shapefiles) in odi_gold\n",
    "output_volume_name = \"global_ml_building_footprints\"\n",
    "output_volume_path = f\"{catalog}.odi_gold.{output_volume_name}\"\n",
    "\n",
    "# Check if volume already exists\n",
    "existing_volumes = spark.sql(f\"SHOW VOLUMES IN {catalog}.odi_gold\").collect()\n",
    "if any(row.volume_name == output_volume_name for row in existing_volumes):\n",
    "    print(f\"Volume {output_volume_path} already exists\")\n",
    "else:\n",
    "    spark.sql(f\"CREATE VOLUME IF NOT EXISTS {output_volume_path}\")\n",
    "    print(f\"Created volume {output_volume_path}\")\n",
    "    print(f\"Access path: /Volumes/{catalog}/odi_gold/{output_volume_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "348fb73e-e3c6-4dec-a11c-dec6f6ec6c00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Verify Setup\n",
    "\n",
    "Run the cell below to verify that the catalog and schemas were created successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "652878a5-28f2-43fd-95fd-b0691f9746ce",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Verify catalog and schemas"
    }
   },
   "outputs": [],
   "source": [
    "# Verify catalog exists\n",
    "print(\"=\" * 60)\n",
    "print(\"CATALOG VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "catalogs = spark.sql(\"SHOW CATALOGS\").collect()\n",
    "if any(row.catalog == catalog for row in catalogs):\n",
    "    print(f\"✓ Catalog '{catalog}' exists\")\n",
    "    \n",
    "    # Get catalog details\n",
    "    catalog_info = spark.sql(f\"DESCRIBE CATALOG EXTENDED {catalog}\").collect()\n",
    "    for row in catalog_info:\n",
    "        if row.info_name == \"Location\":\n",
    "            print(f\"  Location: {row.info_value}\")\n",
    "else:\n",
    "    print(f\"✗ Catalog '{catalog}' not found\")\n",
    "\n",
    "# Verify schemas exist\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SCHEMA VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "for schema in required_schemas:\n",
    "    schemas = spark.sql(f\"SHOW SCHEMAS IN {catalog}\").collect()\n",
    "    if any(row.databaseName == schema for row in schemas):\n",
    "        print(f\"✓ Schema '{catalog}.{schema}' exists\")\n",
    "    else:\n",
    "        print(f\"✗ Schema '{catalog}.{schema}' not found\")\n",
    "\n",
    "# Verify volumes exist\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VOLUME VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check bronze volume\n",
    "volumes_bronze = spark.sql(f\"SHOW VOLUMES IN {catalog}.odi_bronze\").collect()\n",
    "if any(row.volume_name == volume_name for row in volumes_bronze):\n",
    "    print(f\"✓ Volume '{catalog}.odi_bronze.{volume_name}' exists\")\n",
    "    print(f\"  Access path: /Volumes/{catalog}/odi_bronze/{volume_name}\")\n",
    "    print(f\"  State geometries: /Volumes/{catalog}/odi_bronze/{volume_name}/state_geometries\")\n",
    "else:\n",
    "    print(f\"✗ Volume '{catalog}.odi_bronze.{volume_name}' not found\")\n",
    "\n",
    "# Check gold volume\n",
    "volumes_gold = spark.sql(f\"SHOW VOLUMES IN {catalog}.odi_gold\").collect()\n",
    "if any(row.volume_name == output_volume_name for row in volumes_gold):\n",
    "    print(f\"✓ Volume '{catalog}.odi_gold.{output_volume_name}' exists\")\n",
    "    print(f\"  Access path: /Volumes/{catalog}/odi_gold/{output_volume_name}\")\n",
    "else:\n",
    "    print(f\"✗ Volume '{catalog}.odi_gold.{output_volume_name}' not found\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Setup complete! Ready to run ODI building footprints job.\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "create_odi_storage_location_and_schema",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
